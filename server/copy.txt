import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import ratelimit from 'express-rate-limit';
import helmet from 'helmet';
import OpenAI from 'openai';
// import { Configuration, OpenAIApi } from 'openai';
dotenv.config();

const app = express();
app.use(cors());
app.use(express.json({ limit: '10mb' }));
//security middleware
app.use(helmet());
app.use(cors(
  {
    origin: process.env.FRONTEND || 'http://localhost:5500',
    credentials: true,
  }
))


const limiter = ratelimit({
    windowMs: 15 * 60 * 1000, // 15 minutes
    max: 100, // limit each IP to 100 requests per windowMs
    message: 'Too many requests from this IP, please try again after 15 minutes',
    temperature: 0.4,
    maxTokens: 800,
});

const client = new OpenAI({
  baseURL: 'https://api.runpod.ai/v2/granite-4-0-h-small/run',
  apiKey: process.env.API_KEY,
});

app.use(limiter);


app.post('/api/explain-code', async (req, res) => { 
  try {
    const { code, language } = req.body;
    if (!code) {
      return res.status(400).json({ error: 'Code is required' });
    }
    const message = [
      {
        role: 'user',
        content: `Please explain the following ${
          language || ' '
        } Code in simple terms:\n\n${language || ' '} \n${code} \n`,
      },
    ];
    const response = await client.chat.completions.create({
      model: "ibm-granite/granite-4.0-h-small",
      messages: message,
    });

    const explanation = response?.choices?.[0]?.message?.content;
    if (explanation) {
      return res.json({ explanation, language: language || 'unknown' });
    } else {
      return res.status(500).json({ error: 'Failed to get explanation from AI model' });
    }
  } catch (error) {
    console.error(error);
    res.status(500).json({ error: 'Internal Server Error' });
  }
});

const port = process.env.PORT || 5000;

app.listen(port, () => {
    console.log(`Server is running on http://localhost:${port}`);
});
